{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using key from OPENAI_API_KEY_PERSONAL environment variable\n",
      "\n",
      "*** gpt-3.5-turbo trial 0 ***\n",
      "Arr, me matey! A neural network be like a treasure map for the brain, savvy?\n",
      "'Tis a fancy term for a system that be inspired by the way our own noggin works.\n",
      "Just like how we pirates connect different pieces of information to make sense\n",
      "of the seas, a neural network be a network of artificial neurons that be\n",
      "interconnected to process and learn from data. It be a clever way to teach\n",
      "machines to think and make decisions, just like a pirate captain navigates the\n",
      "open waters. So, ye see, a neural network be a powerful tool for us scallywags\n",
      "to uncover hidden treasures in the vast realm of data!\n",
      "\n",
      "*** gpt-3.5-turbo trial 1 ***\n",
      "Arr, me matey! A neural network be a clever contraption inspired by the human\n",
      "brain. It be a system that be designed to learn and make decisions, just like us\n",
      "pirates! It be made up of many interconnected parts called neurons, just like\n",
      "the crew on me ship. These neurons work together to process information and\n",
      "solve problems. It be a powerful tool for understanding patterns and making\n",
      "predictions, me hearties! So, ye see, a neural network be like me trusty\n",
      "compass, helpin' me navigate the treacherous seas of data!\n",
      "\n",
      "*** gpt-4 trial 0 ***\n",
      "Arr matey, a neural network be like a crew of seafarers workin' together. It be\n",
      "a series of algorithms that endeavors to recognize relationships in a set of\n",
      "data through a process that mimics how the human brain works. It's like a\n",
      "treasure map, ye see, finding patterns and connections in the vast ocean of\n",
      "information. Aye, it be a powerful tool in the hands of a savvy data pirate!\n",
      "\n",
      "*** gpt-4 trial 1 ***\n",
      "Arr matey, a neural network be a series of algorithms that attempts to identify\n",
      "underlying relationships in a set of data through a process that mimics the way\n",
      "the human brain operates. It be used in all sorts of technology, from predictin'\n",
      "the weather to recommendin' what ye might want to buy next. It's a bit like\n",
      "havin' a parrot that can predict the future, but a whole lot more complicated!\n",
      "\n",
      "LLM Cache: 4 hits, 0 misses\n",
      "           0 new input tokens, 0 new output tokens, 72 total input tokens, 417 total output tokens\n",
      "           new (this run) API cost: $0.00, total (including previously-cached runs) API cost: $0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\forre\\.virtualenvs\\SoCloverAI-QzWm9qof\\lib\\site-packages\\langchain\\llms\\openai.py:243: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\forre\\.virtualenvs\\SoCloverAI-QzWm9qof\\lib\\site-packages\\langchain\\llms\\openai.py:1038: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\forre\\.virtualenvs\\SoCloverAI-QzWm9qof\\lib\\site-packages\\langchain\\llms\\openai.py:243: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\forre\\.virtualenvs\\SoCloverAI-QzWm9qof\\lib\\site-packages\\langchain\\llms\\openai.py:1038: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "import textwrap\n",
    "import simple_llm_cache\n",
    "import llm_cache_stats_wrapper\n",
    "import os\n",
    "\n",
    "# In order to make it easy to run work projects and personal AI experiments, override OPENAI_API_KEY with the value of OPENAI_API_KEY_PERSONAL if it is set.\n",
    "if \"OPENAI_API_KEY_PERSONAL\" in os.environ:\n",
    "    print(\"Using key from OPENAI_API_KEY_PERSONAL environment variable\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.environ[\"OPENAI_API_KEY_PERSONAL\"]\n",
    "\n",
    "verbose = False\n",
    "temperature = 0.5\n",
    "\n",
    "langchain.llm_cache = llm_cache_stats_wrapper.LlmCacheStatsWrapper(simple_llm_cache.SimpleLlmCache(\"llm-cache.json\"))\n",
    "\n",
    "def dump_cache_stats_since_last_call():\n",
    "    print(langchain.llm_cache.get_cache_stats_summary())\n",
    "    langchain.llm_cache.clear_cache_stats()\n",
    "\n",
    "template = \"\"\"Answer the following question as if you are a {character} character:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt = PromptTemplate(\n",
    "    input_variables=[\"character\", \"question\"],\n",
    "    template=template)\n",
    "\n",
    "for model_name in [\"gpt-3.5-turbo\", \"gpt-4\"]:\n",
    "    llm = OpenAI(\n",
    "        temperature=temperature,\n",
    "        model_name = model_name)\n",
    "\n",
    "    chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=verbose)\n",
    "\n",
    "    for trial in range(2):\n",
    "        print(f\"\\n*** {model_name} trial {trial} ***\")\n",
    "        langchain.llm_cache.inner_cache.set_trial(trial)\n",
    "        output = chain.predict(\n",
    "            character=\"pirate\",\n",
    "            question=\"What is a neural network?\")\n",
    "        print(textwrap.fill(output, width=80))\n",
    "\n",
    "print()\n",
    "dump_cache_stats_since_last_call()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
